{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Analysis\n",
    "Investigate what power to get results we have for various study sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import scipy\n",
    "import numpy\n",
    "from IPython.display import display, HTML\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.cluster import hierarchy\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHORT = 1\n",
    "OUTDIR = f\"../power_analysis/cohort{COHORT}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "full_activity = pandas.read_csv(\"../processed/activity_features_aggregate.txt\", index_col=0, sep=\"\\t\", low_memory=False)\n",
    "activity_summary = pandas.read_csv(\"../processed/activity_summary_aggregate.txt\", index_col=0, sep=\"\\t\", low_memory=False)\n",
    "ukbb = pandas.read_hdf(\"../processed/ukbb_data_table.h5\", low_memory=False)\n",
    "full_mental_health = pandas.read_hdf(\"../processed/ukbb_mental_health.h5\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the activity variables that we don't want to use\n",
    "bad_columns = [\"_IV$\", \"_IS$\", \"^temp_\", \"^light_\"]\n",
    "good_columns = []\n",
    "for c in full_activity.columns:\n",
    "    fail = False\n",
    "    for bad in bad_columns:\n",
    "        if re.search(bad, c):\n",
    "            fail = True\n",
    "    if not fail:\n",
    "        good_columns.append(c)\n",
    "activity = full_activity[good_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 11363 entries out of 103688 due to bad quality or wear-time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tgb\\data\\ukbb\\scripts\\venv\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# drop activity for people who fail basic QC\n",
    "[c for c in activity_summary.columns if 'quality' in c]\n",
    "okay = activity_summary['quality-goodCalibration'].astype(bool) & (~activity_summary['quality-daylightSavingsCrossover'].astype(bool)) & (activity_summary['quality-goodWearTime'].astype(bool))\n",
    "activity.columns = activity.columns.str.replace(\"-\",\"_\") # Can't use special characters easily\n",
    "activity = activity[okay]\n",
    "print(f\"Dropping {(~okay).sum()} entries out of {len(okay)} due to bad quality or wear-time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up column names for mental variables that contain special characters\n",
    "full_mental_health.columns = full_mental_health.columns.str.replace(\"[-',()&/:]\", \"_\") # Can't use special characters easily\n",
    "full_mental_health.drop(columns=[\"date_of_mental_health_questionnaire\",\n",
    "                                 \"birth_month\",\n",
    "                                 \"actigraphy_file\"],\n",
    "                        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data starting size: (92325, 225)\n"
     ]
    }
   ],
   "source": [
    "data = activity.copy()\n",
    "data = data.join(full_mental_health, how=\"left\")\n",
    "\n",
    "covariates = [\"sex\",\n",
    "              #\"ethnicity\",\n",
    "              #\"overall_health\",\n",
    "              #\"household_income\",\n",
    "              #\"smoking\",\n",
    "              \"birth_year\",\n",
    "              #\"BMI\",\n",
    "               #'education_Prefer_not_to_answer', # This answer causes problems for some reason\n",
    "               #'education_None_of_the_above',\n",
    "               #'education_College_or_University_degree',\n",
    "               #'education_A_levels/AS_levels_or_equivalent', \n",
    "               #'education_O_levels/GCSEs_or_equivalent',\n",
    "               #'education_CSEs_or_equivalent',\n",
    "               #'education_NVQ_or_HND_or_HNC_or_equivalent',\n",
    "               #'education_Other_professional_qualifications_eg:_nursing,_teaching',\n",
    "                ]\n",
    "#covariates = [\"BMI\"]\n",
    "#data = data.join(ukbb[covariates], how=\"inner\")\n",
    "\n",
    "print(f\"Data starting size: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tgb\\data\\ukbb\\scripts\\venv\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2023: RuntimeWarning: invalid value encountered in greater\n",
      "  cond1 = (0 < q) & (q < 1)\n",
      "c:\\users\\tgb\\data\\ukbb\\scripts\\venv\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2023: RuntimeWarning: invalid value encountered in less\n",
      "  cond1 = (0 < q) & (q < 1)\n"
     ]
    }
   ],
   "source": [
    "# Many activity variables are highly non-normal shape (long tails and skewed)\n",
    "# We transform those to 'normalized' standard normals by putting them in rank order,\n",
    "# and then taking the corresponding point on the normal distribution inverse cdf\n",
    "activity_norm = activity.select_dtypes(\"number\")\n",
    "import scipy.stats\n",
    "activity_norm.iloc[:,:] = scipy.stats.norm(0,1).isf(1-activity_norm.rank(method=\"first\")/(len(activity_norm)+1))\n",
    "data = data.join(activity_norm, rsuffix=\"_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51257 controls and 44229 cases total.\n",
      "And 21498 controls and 18110 cases with actigraphy\n"
     ]
    }
   ],
   "source": [
    "# Determine a basic set of cases and controls for selecting the samples from\n",
    "control = ((full_mental_health.ever_prolonged_depression == \"No\")\n",
    "           & (full_mental_health.ever_prolonged_loss_of_interest == \"No\")\n",
    "           & (full_mental_health.ever_extreme_irritability == \"No\")\n",
    "           & (full_mental_health.ever_felt_worried_more_than_month == \"No\")\n",
    "           & (full_mental_health.ever_mania == \"No\")\n",
    "          )\n",
    "case = (((full_mental_health.ever_prolonged_depression == \"Yes\")\n",
    "             & (full_mental_health.number_depressed_periods > 2))\n",
    "           | ((full_mental_health.ever_prolonged_loss_of_interest == \"Yes\")\n",
    "               & (full_mental_health.number_depressed_periods > 2))\n",
    "           | ((full_mental_health.ever_worried_much_more == \"Yes\")\n",
    "               & (full_mental_health.impact_normal_roles_worst_anxiety.isin([\"A lot\", \"Somewhat\"])))\n",
    "           | (full_mental_health.every_thought_life_not_worth_living == \"Yes\")\n",
    "           | (full_mental_health.ever_self_harmed == \"Yes\")\n",
    "           | (full_mental_health.ever_attempted_suicide == \"Yes\")\n",
    "           | (full_mental_health.recent_thoughts_of_suicide == \"Yes\")\n",
    "          ) & (~control)\n",
    "print(f\"Found {sum(control)} controls and {sum(case)} cases total.\")\n",
    "\n",
    "data = data.join(pandas.DataFrame({\"control\": control, \"case\": case}), how='left')\n",
    "print(f\"And {sum(data.control)} controls and {sum(data.case)} cases with actigraphy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BH_FDR(ps):\n",
    "    ''' Benjamini-Hochberg FDR control\n",
    "\n",
    "    Converts p values to q values'''\n",
    "\n",
    "    # For the purposes of comparison, an implementation of Benjamini Hochberg correction\n",
    "    sort_order = numpy.argsort(ps)\n",
    "\n",
    "    adjusted = numpy.zeros(ps.shape)\n",
    "    adjusted[sort_order] = numpy.array(ps)[sort_order]*len(ps)/numpy.arange(1,len(ps)+1)\n",
    "\n",
    "    # Make monotone, skipping NaNs\n",
    "    m = 1;\n",
    "    for i, r in enumerate(sort_order[::-1]):\n",
    "        if numpy.isfinite(adjusted[r]):\n",
    "            m = min(adjusted[r], m)\n",
    "            adjusted[r] = m\n",
    "\n",
    "    return adjusted # the q-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the tests to perform\n",
    "Here we create a function that performs the tests we'll run on a given input dataset\n",
    "That way we can easily run this on a variety of samples and sample sizes to determine power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_tests(data, control_expression, mental_health_vars =None):    \n",
    "    # Perform univariate assocation between the actigraphy traits and the binary case/control value\n",
    "    binarized_univariate = {}\n",
    "    for var in activity.columns:\n",
    "        fit = smf.ols(f\"Q('{var}') ~ case + {control_expression}\", data=data).fit()\n",
    "        binarized_univariate[var] = {\n",
    "            \"p\": fit.pvalues[\"case[T.True]\"],\n",
    "            \"coef\": fit.params[\"case[T.True]\"],\n",
    "            \"coef_std\": fit.params[\"case[T.True]\"] / data[var].std()\n",
    "        }\n",
    "    binarized_univarite = pandas.DataFrame(binarized_univariate).T\n",
    "    \n",
    "    if mental_health_vars is None:\n",
    "        mental_health_vars = full_mental_health.columns.intersection(data.columns).difference(covariates)\n",
    "    # Perform univariate associations between a selection of actigrpahy traits\n",
    "    # and a selection of the mental health traits\n",
    "    univariate = {}\n",
    "    fits = {}\n",
    "    bad = False\n",
    "    for mental_health_var in mental_health_vars:\n",
    "        N_var = (~data[mental_health_var].isna()).sum()\n",
    "        if N_var <= 20:\n",
    "            print(f\"Skipping {mental_health_var} due to low data\")\n",
    "            continue\n",
    "\n",
    "        bad = False\n",
    "        for activity_var in (activity_norm.columns + \"_norm\"):      \n",
    "            if bad:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                fit = smf.ols(f\"{activity_var} ~ Q('{mental_health_var}') + {control_expression}\", data=data).fit()\n",
    "                fit2 = smf.ols(f\"{activity_var} ~ {control_expression}\", data=data).fit()\n",
    "            except ValueError:\n",
    "                print(f\"Skipping {mental_health_var}-{activity_var} associations due to missing data\")\n",
    "                continue\n",
    "            if fit.condition_number > 1e4:# or fit.rsquared < 0:\n",
    "                print(f\"Skipping {mental_health_var} associations due to bad numerics\")\n",
    "                bad = True\n",
    "                continue\n",
    "            f, p, df = fit.compare_f_test(fit2)\n",
    "            \n",
    "            univariate[(mental_health_var, activity_var)] = {\n",
    "                \"p\": p,\n",
    "                \"N\": N_var,\n",
    "                \"cond_num\": fit.condition_number\n",
    "            }\n",
    "            \n",
    "            fits[(mental_health_var, activity_var)] = fit\n",
    "\n",
    "    univariate = pandas.DataFrame(univariate).T\n",
    "    return binarized_univarite, univariate, fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping actions_taken_following_self_harm_Prefer_not_to_answer associations due to bad numerics\n",
      "Skipping activities_to_treat_anxiety_Prefer_not_to_answer associations due to bad numerics\n",
      "Skipping activities_to_treat_depression_Prefer_not_to_answer associations due to bad numerics\n",
      "Skipping assessment_center associations due to bad numerics\n",
      "Skipping attempted_suicide_past_year associations due to bad numerics\n",
      "Skipping avoided_activities_because_of_stressful_experience_past_month associations due to bad numerics\n",
      "Skipping been_in_combat_war_zone associations due to bad numerics\n",
      "Skipping been_in_series_accident associations due to bad numerics\n",
      "Skipping behavior_misc_addictions_A_behaviour due to low data\n",
      "Skipping behavior_misc_addictions_Prefer_not_to_answer due to low data\n",
      "Skipping behavior_misc_addictions_Something_else_not_mentioned due to low data\n",
      "Skipping belittlement_by_partner_as_adult associations due to bad numerics\n",
      "Skipping contemplated_self_harm_last_year associations due to bad numerics\n",
      "Skipping depression_related_to_childbirth associations due to bad numerics\n",
      "Skipping difficulty_concentrating_worst_episode associations due to bad numerics\n",
      "Skipping difficulty_stopping_worrying_worst_anxiety associations due to bad numerics\n",
      "Skipping disturbing_thoughts_past_month associations due to bad numerics\n",
      "Skipping ever_addicted_alcohol associations due to bad numerics\n",
      "Skipping ever_addicted_behavior_misc associations due to bad numerics\n",
      "Skipping ever_addicted_drugs associations due to bad numerics\n",
      "Skipping ever_addicted_medication associations due to bad numerics\n",
      "Skipping ever_extreme_irritability associations due to bad numerics\n",
      "Skipping ever_mania associations due to bad numerics\n",
      "Skipping ever_mental_distress_prevent_activities associations due to bad numerics\n",
      "Skipping ever_physically_dependent_on_alcohol associations due to bad numerics\n",
      "Skipping ever_took_cannabis associations due to bad numerics\n",
      "Skipping ever_worried_much_more associations due to bad numerics\n",
      "Skipping felt_upset_when_reminded_of_experience_past_month associations due to bad numerics\n",
      "Skipping fraction_of_day_worst_episode associations due to bad numerics\n",
      "Skipping freq_of_difficulty_controlling_worry_worst_anxiety associations due to bad numerics\n",
      "Skipping freq_of_inability_to_stop_worrying_worst_anxiety associations due to bad numerics\n",
      "Skipping frequency_depressed_days_worst_episode associations due to bad numerics\n",
      "Skipping happiness_with_health associations due to bad numerics\n",
      "Skipping impact_normal_roles_worst_anxiety associations due to bad numerics\n",
      "Skipping impact_on_normal_roles_worst_episode associations due to bad numerics\n",
      "Skipping mental_health_problems_diagnosed_Prefer_not_to_answer__group_A_ associations due to bad numerics\n",
      "Skipping methods_of_self_harm_used_Prefer_not_to_answer associations due to bad numerics\n",
      "Skipping multiple_worries_worst_anxiety associations due to bad numerics\n",
      "Skipping ongoing_addiction_behavior_misc due to low data\n",
      "Skipping ongoing_addiction_drug due to low data\n",
      "Skipping ongoing_addiction_medication due to low data\n",
      "Skipping physically_abused_by_family_as_child associations due to bad numerics\n",
      "Skipping professional_informed_about_depression associations due to bad numerics\n",
      "Skipping professional_informed_anxiety associations due to bad numerics\n",
      "Skipping recent_changes_in_speed associations due to bad numerics\n",
      "Skipping recent_feeling_tired_low_energy associations due to bad numerics\n",
      "Skipping recent_foreboding associations due to bad numerics\n",
      "Skipping recent_poor_appetite_overeating associations due to bad numerics\n",
      "Skipping recent_trouble_relaxing associations due to bad numerics\n",
      "Skipping recent_uncontrollable_worrying associations due to bad numerics\n",
      "Skipping self_harmed_past_year associations due to bad numerics\n",
      "Skipping sleep_change_worst_episode associations due to bad numerics\n",
      "Skipping sought_professional_help_mental_distress associations due to bad numerics\n",
      "Skipping stronger_worrying_anxiety associations due to bad numerics\n",
      "Skipping substance_of_addiction_A_painkiller due to low data\n",
      "Skipping substance_of_addiction_A_sedative__benzodiazepine_or_sleeping_tablet due to low data\n",
      "Skipping substance_of_addiction_Do_not_know due to low data\n",
      "Skipping substance_of_addiction_Prefer_not_to_answer due to low data\n",
      "Skipping substance_of_addiction_Something_else due to low data\n",
      "Skipping substances_taken_anxiety_Prefer_not_to_answer associations due to bad numerics\n",
      "Skipping thoughts_of_death_worst_episode associations due to bad numerics\n",
      "Skipping tiredness_worst_episode associations due to bad numerics\n",
      "Skipping victim_of_sexual_assault associations due to bad numerics\n",
      "Skipping weight_change_worst_episode associations due to bad numerics\n",
      "Skipping worried_most_days_worst_anxiety associations due to bad numerics\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-a968eb8bcdca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;34m\"N_case\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;34m\"best_p_binarized\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbest_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[1;34m\"num_significant_binarized\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnum_significant\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     }\n\u001b[0;32m     27\u001b[0m     \u001b[0mfull_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults_binary_univariate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults_univariate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tgb\\data\\ukbb\\scripts\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3467\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3469\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tgb\\data\\ukbb\\scripts\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3543\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3544\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3545\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tgb\\data\\ukbb\\scripts\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3728\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3729\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3730\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3731\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tgb\\data\\ukbb\\scripts\\venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Length of values does not match length of index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "def sample(data, N_cases, N_controls):\n",
    "    case_sample = data[data.case].sample(N_cases)\n",
    "    control_sample = data[data.control].sample(N_controls)\n",
    "    return pandas.concat([case_sample, control_sample])\n",
    "\n",
    "Ns = [(100,25), (100,100), (200, 200), (300, 300), (400,400), (500, 500), (1000, 1000), (2000, 2000), (5000, 5000)]\n",
    "results = {}\n",
    "full_results = {}\n",
    "for N in Ns:\n",
    "\n",
    "    results_binary_univariate, results_univariate, fits = perform_tests(sample(data, *N), \"sex + standardize(birth_year)\")\n",
    "    \n",
    "    best_p_binary = results_binary_univariate.p.min()\n",
    "    num_significant_binary = numpy.sum(results_binary_univariate.p*len(results_binary_univariate) < 0.05)\n",
    "    \n",
    "    best_p = results_univariate.p.min()\n",
    "    num_significant = numpy.sum(results_univariate.p*len(results_univariate) < 0.05)\n",
    "    \n",
    "    results[N] = {\n",
    "        \"N_control\": N[0],\n",
    "        \"N_case\": N[1],\n",
    "        \"best_p_binarized\": best_p,\n",
    "        \"num_significant_binarized\": num_significant\n",
    "    }\n",
    "    full_results[N] = (results_binary_univariate, results_univariate, fits)\n",
    "results = pandas.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for binary, all_, fits in full_results.values():\n",
    "    binary['q'] = BH_FDR(binary['p'])\n",
    "    all_['q'] = BH_FDR(all_['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results[(500,500)][0].sort_values(by=\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_q = pandas.Series(\n",
    "    {N: df.q.min() for N,(df,_,_) in full_results.items()},\n",
    "    name=\"Best q\"\n",
    ")\n",
    "n_significant = pandas.Series(\n",
    "    {N: (df.q < 0.1).sum() for N,(df,_,_) in full_results.items()},\n",
    "    name=\"Num q < 0.1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "12\n",
      "30\n",
      "35\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([str(x) for n,x in n_significant.iteritems()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
